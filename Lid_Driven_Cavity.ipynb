{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Used following code for ref:\n",
        "\n",
        "*   https://github.com/amir-cardiolab/PINN_multiphysics_multifidelity/blob/main/2D_Lid_driven_cavity/Lid_driven_cavity_Initialization.py\n",
        "*   https://github.com/okada39/pinn_cavity/blob/master/main.py\n",
        "*   NS Youtube: https://github.com/ComputationalDomain/PINNs\n",
        "\n"
      ],
      "metadata": {
        "id": "IF2UbK33Mnzs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EQUATIONS:\n",
        "*   **Eqn:**\n",
        "\n",
        "*   u_x + v_y = 0,\n",
        "*   u*u_x + v*u_y + p_x/rho - nu*(u_xx + u_yy) = 0,\n",
        "*   u*v_x + v*v_y + p_y/rho - nu*(v_xx + v_yy) = 0,\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   **BCS:**\n",
        "\n",
        "*   x, y = 0 ~ 1:\n",
        "*   u=1, v=0 at top boundary\n",
        "*   u=0, v=0 at other boundaries\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Vqt6trPTN0gC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# IMPORTS:"
      ],
      "metadata": {
        "id": "qt053KmtNCfR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PykVNKkMMdOH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from math import exp, sqrt,pi\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import Normalize\n",
        "from matplotlib.gridspec import GridSpec\n",
        "\n",
        "import tqdm as tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CONSTANTS"
      ],
      "metadata": {
        "id": "-ECsybHpn25h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rho = 1\n",
        "nu = 0.01\n",
        "\n",
        "num_train_samples = 10000\n",
        "num_bc_samples = 2500\n",
        "epochs = 1000\n",
        "lr = 0.001\n",
        "\n",
        "load_checkpoint = True"
      ],
      "metadata": {
        "id": "PiTPYhSWn5YJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MODEL"
      ],
      "metadata": {
        "id": "Qv8y36p6VcJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(2, 20), nn.Tanh(),\n",
        "            nn.Linear(20, 20), nn.Tanh(),\n",
        "            nn.Linear(20, 20), nn.Tanh(),\n",
        "            nn.Linear(20, 20), nn.Tanh(),\n",
        "            nn.Linear(20, 20), nn.Tanh(),\n",
        "            nn.Linear(20, 20), nn.Tanh(),\n",
        "            nn.Linear(20, 20), nn.Tanh(),\n",
        "            nn.Linear(20, 20), nn.Tanh(),\n",
        "            nn.Linear(20, 20), nn.Tanh(),\n",
        "            nn.Linear(20, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        input = torch.cat([x,y], axis = 1)\n",
        "        output = self.net(input)\n",
        "        #output = self.net(input)\n",
        "        return output\n"
      ],
      "metadata": {
        "id": "hKSQif5QVbWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = Net()\n",
        "net = net.to(device)\n",
        "\n",
        "mse_loss_fn = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters())"
      ],
      "metadata": {
        "id": "dElauzYbWln-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def checkpoint(state,filename=\"checkpt.pth\"):\n",
        "     print('\\n',\"Saving checkpoint\")\n",
        "     torch.save(state,filename)\n",
        "\n",
        "def load_checkpt(checkpt):\n",
        "     print('\\n',\"Loading checkpoint\")\n",
        "     checkpt = torch.load(\"checkpt.pth\")\n",
        "     net.load_state_dict(checkpt['state_dict'])\n",
        "     optimizer.load_state_dict(checkpt['optimizer_dict'])\n",
        "     net.train()"
      ],
      "metadata": {
        "id": "uQRwsbNd0XPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PDE"
      ],
      "metadata": {
        "id": "-lSYUTgFj9Sx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Pde(x,y,net):\n",
        "  #print('psi from pde fun', '\\n', psi)\n",
        "\n",
        "  u = torch.autograd.grad(psi, y, grad_outputs=torch.ones_like(psi), create_graph=True)[0]\n",
        "  v = -1 * torch.autograd.grad(psi, x, grad_outputs=torch.ones_like(psi), create_graph=True)[0]\n",
        "\n",
        "  u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
        "  u_xx = torch.autograd.grad(u_x, x, grad_outputs=torch.ones_like(u_x), create_graph=True)[0]\n",
        "  u_y = torch.autograd.grad(u, y, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
        "  u_yy = torch.autograd.grad(u_y, y, grad_outputs=torch.ones_like(u_y), create_graph=True)[0]\n",
        "\n",
        "\n",
        "  v_x = torch.autograd.grad(v, x, grad_outputs=torch.ones_like(v), create_graph=True)[0]\n",
        "  v_xx = torch.autograd.grad(v_x, x, grad_outputs=torch.ones_like(v_x), create_graph=True)[0]\n",
        "  v_y = torch.autograd.grad(v, y, grad_outputs=torch.ones_like(v), create_graph=True)[0]\n",
        "  v_yy = torch.autograd.grad(v_y, y, grad_outputs=torch.ones_like(v_y), create_graph=True)[0]\n",
        "\n",
        "\n",
        "  p_x = torch.autograd.grad(p, x, grad_outputs=torch.ones_like(p), create_graph=True)[0]\n",
        "  p_y = torch.autograd.grad(p, y, grad_outputs=torch.ones_like(p), create_graph=True)[0]\n",
        "\n",
        "  continuity_pde_out = u_x + v_y\n",
        "  x_dir_ns_pde_out = u*u_x + v*u_y + p_x/rho - nu*(u_xx + u_yy)\n",
        "  y_dir_ns_pde_out = u*v_x + v*v_y + p_y/rho - nu*(v_xx + v_yy)\n",
        "\n",
        "  pde_out = [continuity_pde_out, x_dir_ns_pde_out, y_dir_ns_pde_out, u, v]\n",
        "  return pde_out"
      ],
      "metadata": {
        "id": "rXNBo3ezkBfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_uv(x,y,net_out):\n",
        "  psi, p = torch.split(net_out, split_size_or_sections=1, dim=1)\n",
        "\n",
        "  u = torch.autograd.grad(psi, y, grad_outputs=torch.ones_like(psi), create_graph=True)[0]\n",
        "  v = -1 * torch.autograd.grad(psi, x, grad_outputs=torch.ones_like(psi), create_graph=True)[0]\n",
        "\n",
        "  predicted_vel = torch.cat([u,v], axis = 1)\n",
        "  return predicted_vel"
      ],
      "metadata": {
        "id": "KxESQDIAs0Bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BOUNDARY CONDITIONS:"
      ],
      "metadata": {
        "id": "_tyxs9qispRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lid BCs:\n",
        "lid_train_pts = np.random.rand(num_bc_samples, 2)\n",
        "lid_train_pts[:,1:2] = 1\n",
        "\n",
        "lid_labels = np.zeros((num_bc_samples,2))\n",
        "lid_labels[:,0:1] = 1\n",
        "\n",
        "lid_train_pts_device = torch.from_numpy(lid_train_pts).float().to(device)\n",
        "lid_train_pts_device.requires_grad = True\n",
        "x_lid, y_lid = torch.split(lid_train_pts_device, split_size_or_sections=1, dim=1)  # input data for lid bc to network\n",
        "\n",
        "lid_labels_device = torch.from_numpy(lid_labels).float().to(device)\n",
        "\n",
        "\n",
        "# Left wall BCs:\n",
        "lw_train_pts = np.random.rand(num_bc_samples, 2)\n",
        "lw_train_pts[:,0:1] = 0\n",
        "\n",
        "lw_labels = np.zeros((num_bc_samples,2))\n",
        "\n",
        "lw_train_pts_device = torch.from_numpy(lw_train_pts).float().to(device)\n",
        "lw_train_pts_device.requires_grad = True\n",
        "x_lw, y_lw = torch.split(lw_train_pts_device, split_size_or_sections=1, dim=1)    # input data for lw bc to  network\n",
        "\n",
        "lw_labels_device = torch.from_numpy(lw_labels).float().to(device)\n",
        "\n",
        "\n",
        "# Right wall BCs:\n",
        "rw_train_pts = np.random.rand(num_bc_samples, 2)\n",
        "rw_train_pts[:,0:1] = 1\n",
        "\n",
        "rw_labels = np.zeros((num_bc_samples,2))\n",
        "\n",
        "rw_train_pts_device = torch.from_numpy(rw_train_pts).float().to(device)\n",
        "rw_train_pts_device.requires_grad = True\n",
        "x_rw, y_rw = torch.split(rw_train_pts_device, split_size_or_sections=1, dim=1)    # input data for rw bc to  network\n",
        "\n",
        "rw_labels_device = torch.from_numpy(rw_labels).float().to(device)\n",
        "\n",
        "\n",
        "# Lower wall BCs:\n",
        "btm_train_pts = np.random.rand(num_bc_samples, 2)\n",
        "btm_train_pts[:,1:2] = 0\n",
        "\n",
        "btm_labels = np.zeros((num_bc_samples,2))\n",
        "\n",
        "btm_train_pts_device = torch.from_numpy(btm_train_pts).float().to(device)\n",
        "btm_train_pts_device.requires_grad = True\n",
        "x_btm, y_btm = torch.split(btm_train_pts_device, split_size_or_sections=1, dim=1)    # input data for lower wall bc to  network\n",
        "\n",
        "btm_labels_device = torch.from_numpy(btm_labels).float().to(device)\n"
      ],
      "metadata": {
        "id": "DPEMx6vLomK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CREATING TRAINING POINTS:"
      ],
      "metadata": {
        "id": "cfXrnA4WWOOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_pts = np.random.rand(num_train_samples, 2)\n",
        "train_pts_device = torch.from_numpy(train_pts).float().to(device)\n",
        "train_pts_device.requires_grad = True\n",
        "\n",
        "train_labels = np.zeros((num_train_samples,1))\n",
        "train_labels_device = torch.from_numpy(train_labels).float().to(device)"
      ],
      "metadata": {
        "id": "2MGmt9vDWTw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Loop:"
      ],
      "metadata": {
        "id": "YzpXpDqbBphA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exp_train = np.random.rand(num_bc_samples, 2)\n",
        "exp_train_device = torch.from_numpy(exp_train).float().to(device)\n",
        "\n",
        "x_exp, y_exp = torch.split(exp_train_device, split_size_or_sections=1, dim=1)\n",
        "exp_out1 = net(x_exp, y_exp)\n",
        "print(exp_out1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTTnN1GpFI2h",
        "outputId": "28926fb7-0fc2-4b45-ee81-84b0a722b5d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.0000e+00, 2.3842e-07],\n",
            "        [1.0000e+00, 2.0862e-07],\n",
            "        [1.0000e+00, 2.6822e-07],\n",
            "        ...,\n",
            "        [1.0000e+00, 2.3842e-07],\n",
            "        [1.0000e+00, 2.2352e-07],\n",
            "        [1.0000e+00, 2.9802e-07]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if load_checkpoint == True:\n",
        "  checkpoint = torch.load('net.pth', map_location = device)\n",
        "  net.load_state_dict(checkpoint)"
      ],
      "metadata": {
        "id": "LAr6s-uy1WjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "\n",
        "\n",
        "  #----------------------------BOUNDARY CONDITION LOSS CALCULATION------------------------------#\n",
        "\n",
        "  # lid:\n",
        "  net_lid_bc_out = net(x_lid, y_lid)\n",
        "\n",
        "  lid_predicted_vel = get_uv(x_lid, y_lid, net_lid_bc_out)\n",
        "  j_lid = mse_loss_fn(lid_predicted_vel, lid_labels_device)\n",
        "\n",
        "  # left-wall:\n",
        "  net_lw_bc_out = net(x_lw, y_lw)\n",
        "  lw_predicted = get_uv(x_lw, y_lw, net_lw_bc_out)\n",
        "  j_lw = mse_loss_fn(lw_predicted, lw_labels_device)\n",
        "\n",
        "  # right-wall:\n",
        "  net_rw_bc_out = net(x_rw, y_rw)\n",
        "  rw_predicted = get_uv(x_rw, y_rw, net_rw_bc_out)\n",
        "  j_rw = mse_loss_fn(rw_predicted, rw_labels_device)\n",
        "\n",
        "  # lower wall:\n",
        "  net_btm_bc_out = net(x_btm, y_btm)\n",
        "  btm_predicted = get_uv(x_btm, y_btm, net_btm_bc_out)\n",
        "  j_btm = mse_loss_fn(btm_predicted, btm_labels_device)\n",
        "\n",
        "\n",
        "  J_BC = j_lid + j_lw + j_rw + j_btm    # total BC loss\n",
        "  #----------------------------------------------------------------------------------------------#\n",
        "\n",
        "\n",
        "\n",
        "  #----------------------------PDE LOSS CALCULATION------------------------------#\n",
        "  xy = train_pts_device\n",
        "  x, y = torch.split(xy, split_size_or_sections=1, dim=1)    # input data for lw bc to  network\n",
        "  xy.requires_grad = True\n",
        "\n",
        "  output = net(x,y)\n",
        "  psi = output[:,0:1]\n",
        "  #print('psi from output slice', '\\n', psi)\n",
        "  p = output[:,1:2]\n",
        "\n",
        "  pde_outputs = Pde(x,y,net)\n",
        "\n",
        "  j_continuity = mse_loss_fn(pde_outputs[0], train_labels_device)\n",
        "  j_ns_x = mse_loss_fn(pde_outputs[1], train_labels_device)\n",
        "  j_ns_y = mse_loss_fn(pde_outputs[2], train_labels_device)\n",
        "\n",
        "\n",
        "  J_PDE = j_continuity + j_ns_x + j_ns_y\n",
        "  #----------------------------------------------------------------------------------------------#\n",
        "\n",
        "\n",
        "\n",
        "  total_loss = J_BC + J_PDE\n",
        "\n",
        "  total_loss.backward()\n",
        "\n",
        "  optimizer.step()\n",
        "\n",
        "  with torch.autograd.no_grad():\n",
        "    \tprint(epoch,\"Training Loss:\", total_loss.data)\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    torch.save(net.state_dict(), 'net.pth')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1yDxm3cyxDto",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c992bb30-3008-45de-b502-f36938827ab1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 Training Loss: tensor(0.0386)\n",
            "1 Training Loss: tensor(0.2652)\n",
            "2 Training Loss: tensor(0.0665)\n",
            "3 Training Loss: tensor(0.1610)\n",
            "4 Training Loss: tensor(0.0998)\n",
            "5 Training Loss: tensor(0.0402)\n",
            "6 Training Loss: tensor(0.0630)\n",
            "7 Training Loss: tensor(0.0915)\n",
            "8 Training Loss: tensor(0.0948)\n",
            "9 Training Loss: tensor(0.0770)\n",
            "10 Training Loss: tensor(0.0537)\n",
            "11 Training Loss: tensor(0.0435)\n",
            "12 Training Loss: tensor(0.0545)\n",
            "13 Training Loss: tensor(0.0699)\n",
            "14 Training Loss: tensor(0.0676)\n",
            "15 Training Loss: tensor(0.0533)\n",
            "16 Training Loss: tensor(0.0450)\n",
            "17 Training Loss: tensor(0.0478)\n",
            "18 Training Loss: tensor(0.0550)\n",
            "19 Training Loss: tensor(0.0592)\n",
            "20 Training Loss: tensor(0.0573)\n",
            "21 Training Loss: tensor(0.0512)\n",
            "22 Training Loss: tensor(0.0456)\n",
            "23 Training Loss: tensor(0.0450)\n",
            "24 Training Loss: tensor(0.0490)\n",
            "25 Training Loss: tensor(0.0520)\n",
            "26 Training Loss: tensor(0.0498)\n",
            "27 Training Loss: tensor(0.0453)\n",
            "28 Training Loss: tensor(0.0432)\n",
            "29 Training Loss: tensor(0.0446)\n",
            "30 Training Loss: tensor(0.0469)\n",
            "31 Training Loss: tensor(0.0470)\n",
            "32 Training Loss: tensor(0.0448)\n",
            "33 Training Loss: tensor(0.0423)\n",
            "34 Training Loss: tensor(0.0420)\n",
            "35 Training Loss: tensor(0.0435)\n",
            "36 Training Loss: tensor(0.0442)\n",
            "37 Training Loss: tensor(0.0427)\n",
            "38 Training Loss: tensor(0.0410)\n",
            "39 Training Loss: tensor(0.0411)\n",
            "40 Training Loss: tensor(0.0421)\n",
            "41 Training Loss: tensor(0.0422)\n",
            "42 Training Loss: tensor(0.0411)\n",
            "43 Training Loss: tensor(0.0401)\n",
            "44 Training Loss: tensor(0.0405)\n",
            "45 Training Loss: tensor(0.0412)\n",
            "46 Training Loss: tensor(0.0407)\n",
            "47 Training Loss: tensor(0.0398)\n",
            "48 Training Loss: tensor(0.0397)\n",
            "49 Training Loss: tensor(0.0402)\n",
            "50 Training Loss: tensor(0.0401)\n",
            "51 Training Loss: tensor(0.0395)\n",
            "52 Training Loss: tensor(0.0393)\n",
            "53 Training Loss: tensor(0.0396)\n",
            "54 Training Loss: tensor(0.0396)\n",
            "55 Training Loss: tensor(0.0391)\n",
            "56 Training Loss: tensor(0.0390)\n",
            "57 Training Loss: tensor(0.0392)\n",
            "58 Training Loss: tensor(0.0392)\n",
            "59 Training Loss: tensor(0.0389)\n",
            "60 Training Loss: tensor(0.0388)\n",
            "61 Training Loss: tensor(0.0390)\n",
            "62 Training Loss: tensor(0.0389)\n",
            "63 Training Loss: tensor(0.0387)\n",
            "64 Training Loss: tensor(0.0387)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-a8a0a84b1d8d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m   \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJ_BC\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mJ_PDE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m   \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n\u001b[0;32m--> 492\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    493\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plotting:"
      ],
      "metadata": {
        "id": "tWNNqwWn7NTT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_coords = np.linspace(0, 1, num_train_samples)\n",
        "y_coords = np.linspace(0, 1, num_train_samples)\n",
        "\n",
        "x_m, y_m = np.meshgrid(x_coords, y_coords)\n",
        "xy_coords = np.stack([x.flatten(), y.flatten()], axis=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpZwPUD16zXM",
        "outputId": "41eada61-b40e-45b3-c224-79bd3cde2f85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 10000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "X_qNniwJ7l96"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}